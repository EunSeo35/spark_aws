{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e13f5501-6153-48dc-b1f8-e7f9714f25b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/11 10:29:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# SparkSession 생성\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"241211_01_SparkSQL_SQLtest\") \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0867c04-58ca-4280-86ac-51731fee879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "\n",
    "user_data = [\n",
    "    Row(user_id=1, username='A', address='서울'),\n",
    "    Row(user_id=2, username='B', address='대전'),\n",
    "    Row(user_id=3, username='C', address='경기도'),\n",
    "    Row(user_id=4, username='D', address=None),\n",
    "    Row(user_id=5, username='E', address=None),\n",
    "    Row(user_id=6, username='F', address='서울'),\n",
    "    Row(user_id=7, username='G', address='경기도'),\n",
    "    Row(user_id=8, username='H', address='대구'),\n",
    "    Row(user_id=9, username='I', address='부산'),\n",
    "    Row(user_id=10, username='J', address='전주'),\n",
    "    Row(user_id=11, username='K', address='광주')\n",
    "]\n",
    "\n",
    "\n",
    "books_data = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "251a0770-7d6b-4635-834f-6476e1cd4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dataframe 생성 및 sql 테이블 생성 \n",
    "\n",
    "user_df = spark.createDataFrame(user_data)\n",
    "user_df.createOrReplaceTempView('users')\n",
    "\n",
    "book_df = spark.createDataFrame(books_data)\n",
    "book_df.createOrReplaceTempView('books')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "083551a2-ae03-4505-a79c-56170e8b686d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 0:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-------+\n",
      "|user_id|username|address|\n",
      "+-------+--------+-------+\n",
      "|      1|       A|   서울|\n",
      "|      2|       B|   대전|\n",
      "|      3|       C| 경기도|\n",
      "|      4|       D|   null|\n",
      "|      5|       E|   null|\n",
      "|      6|       F|   서울|\n",
      "|      7|       G| 경기도|\n",
      "|      8|       H|   대구|\n",
      "|      9|       I|   부산|\n",
      "|     10|       J|   전주|\n",
      "|     11|       K|   광주|\n",
      "+-------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    '''\n",
    "    select * from users;\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64810f87-43ef-4fe2-abd9-623a3b94509b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+\n",
      "|username| address|\n",
      "+--------+--------+\n",
      "|       A|    서울|\n",
      "|       B|    대전|\n",
      "|       C|  경기도|\n",
      "|       D|주소없음|\n",
      "|       E|주소없음|\n",
      "|       F|    서울|\n",
      "|       G|  경기도|\n",
      "|       H|    대구|\n",
      "|       I|    부산|\n",
      "|       J|    전주|\n",
      "|       K|    광주|\n",
      "+--------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    '''\n",
    "    select username,\n",
    "        IF(address IS NULL, '주소없음', address) AS address\n",
    "    From users;\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "25248463-144f-47b8-b65f-c1907f504a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            20|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    '''\n",
    "    select *\n",
    "    from books\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8708879d-4a2a-45a4-a940-b3eff8a35372",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 없음|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_1= spark.sql(\n",
    "    '''\n",
    "        SELECT stock_quantity, \n",
    "    \t   IF(stock_quantity >= 50, '재고 많음',\n",
    "    \t   IF(stock_quantity >= 30, '재고 중간', '재고 없음')) AS quantity_level\n",
    "        FROM books;\n",
    "    '''\n",
    ")\n",
    "books_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2587b21d-306d-4572-9b8a-da3678a2d506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|stock_quantity|quantity_level|\n",
      "+--------------+--------------+\n",
      "|            55|     재고 많음|\n",
      "|            40|     재고 중간|\n",
      "|            20|     재고 부족|\n",
      "|            75|     재고 많음|\n",
      "|            35|     재고 중간|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_2 = spark.sql(\n",
    "    '''\n",
    "        SELECT stock_quantity, \n",
    "            CASE\n",
    "                WHEN stock_quantity >= 50 THEN '재고 많음'\n",
    "                WHEN stock_quantity >= 30 THEN '재고 중간'\n",
    "                ELSE '재고 부족'\n",
    "            END AS quantity_level\n",
    "        FROM books;\n",
    "    '''\n",
    ")\n",
    "books_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b35e45d5-b3f4-4e9c-870d-113b2b7b539f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#53L, if ((stock_quantity#53L >= 50)) 재고 많음 else if ((stock_quantity#53L >= 30)) 재고 중간 else 재고 없음 AS quantity_level#223]\n",
      "+- *(1) Scan ExistingRDD[book_id#47L,title#48,author_fname#49,author_lname#50,pages#51L,released_year#52L,stock_quantity#53L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실행결과 비교\n",
    "books_1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "66c80cba-3881-438b-a7e4-606b56fc8545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [stock_quantity#53L, CASE WHEN (stock_quantity#53L >= 50) THEN 재고 많음 WHEN (stock_quantity#53L >= 30) THEN 재고 중간 ELSE 재고 부족 END AS quantity_level#235]\n",
      "+- *(1) Scan ExistingRDD[book_id#47L,title#48,author_fname#49,author_lname#50,pages#51L,released_year#52L,stock_quantity#53L]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_2.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "14890101-a890-4e95-8a2e-d39073649422",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------+\n",
      "|author_lname|count(1)|\n",
      "+------------+--------+\n",
      "|       Jones|       1|\n",
      "|       Davis|       1|\n",
      "|       Smith|       1|\n",
      "|         Doe|       1|\n",
      "|       Brown|       1|\n",
      "+------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql( \n",
    "    '''\n",
    "    select author_lname, count(*)\n",
    "    from books\n",
    "    group by author_lname;\n",
    "'''\n",
    "\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "01fc61b5-b4c0-4357-b75a-0ea22e074721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# books 테이블 데이터에 borrowed_by 추가\n",
    "books_data_with_user = [\n",
    "    Row(book_id=1, title=\"Book A\", author_fname=\"John\", author_lname=\"Doe\", pages=300, released_year=2005, stock_quantity=55, borrowed_by=1),\n",
    "    Row(book_id=2, title=\"Book B\", author_fname=\"Jane\", author_lname=\"Smith\", pages=250, released_year=2010, stock_quantity=40, borrowed_by=2),\n",
    "    Row(book_id=3, title=\"Book C\", author_fname=\"Emily\", author_lname=\"Jones\", pages=180, released_year=2015, stock_quantity=20, borrowed_by=3),\n",
    "    Row(book_id=4, title=\"Book D\", author_fname=\"Chris\", author_lname=\"Brown\", pages=320, released_year=2012, stock_quantity=75, borrowed_by=None),\n",
    "    Row(book_id=5, title=\"Book E\", author_fname=\"Anna\", author_lname=\"Davis\", pages=270, released_year=2008, stock_quantity=35, borrowed_by=6)\n",
    "]\n",
    "\n",
    "\n",
    "books_df_with_user = spark.createDataFrame(books_data_with_user)\n",
    "books_df_with_user.createOrReplaceTempView(\"books\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "12ee8215-b2bb-485d-b6e9-9c5ebdb2286f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import when, lit\n",
    "\n",
    "# borrowed_by 컬럼 추가 및 데이터 입력\n",
    "updated_books_df = book_df.withColumn(\n",
    "    \"borrowed_by\",\n",
    "    when(book_df.book_id == 1, 1)\n",
    "    .when(book_df.book_id == 2, 2)\n",
    "    .when(book_df.book_id == 3, 3)\n",
    "    .when(book_df.book_id == 4, lit(None))\n",
    "    .when(book_df.book_id == 5, 6)\n",
    "    .otherwise(None)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0ae07ffa-fcc8-413b-98d0-5caaf7d18c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            20|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "books_sql = spark.sql(\n",
    "    '''\n",
    "    select * \n",
    "    from books\n",
    "    '''\n",
    ")\n",
    "\n",
    "books_sql.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "faeac3a5-58a3-4a01-9944-1efdfb4f6b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book_id = 3, stock_quantity = 50으로 바꾼다. \n",
    "#sql의 update set과 같음\n",
    "\n",
    "\n",
    "updated_books_df = books_df_with_user.withColumn( \n",
    "    'stock_quantity', \n",
    "    when(books_df_with_user.book_id == 3, 50).otherwise(books_df_with_user.stock_quantity)\n",
    ")\n",
    "\n",
    "updated_books_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "905af083-e69f-431a-89fb-eb6ee7214693",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (992090041.py, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[50], line 5\u001b[0;36m\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#stock_quantity 10% 증가\n",
    "books_df_with_user.withColumn(\n",
    "    'stock_quantity',\n",
    "    books_df_with_user.stock_quantity = books_df_with_user.stock_quantity*10%\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e4b0d9e2-97a2-4209-b94d-8e636cdf08af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#뷰로 등록\n",
    "updated_books_df.createOrReplaceTempView(\"books\")\n",
    "spark.sql(\"select * from books\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd0dc5e-9197-4103-9252-d7b4f702be39",
   "metadata": {},
   "source": [
    "## 데이터 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f2770168-0b20-49ab-a363-3bdcaed1bfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#write의 저장 mode: overwrite, append, ignore, error\n",
    "\n",
    "updated_books_df.write.csv(\"data/output/sqltest_updated_books.csv\", header = True, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2f66e5a9-f29c-4b2e-8beb-503c963e89db",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.write.csv(\"data/output/sqltest_updated_users.csv\", header = True, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c8b46e-eb6c-4d39-adaf-823ffab77bc3",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "715e7145-bada-4250-aef6-ac475a4a93bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "updated_books_df1 = spark.read.csv(\"data/output/sqltest_updated_books.csv\", header = True)\n",
    "updated_books_df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fbf0105d-d347-41b1-94c7-6a668fbb1342",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df1 = spark.read.csv(\"data/output/sqltest_updated_users.csv\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a379fa6-1b45-438f-ad92-e6e02a8af0ff",
   "metadata": {},
   "source": [
    "## 조인 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8e549c4-a3b0-48d9-87dc-90fe91fc8224",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:================================================>     (179 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 1. INNER JOIN\n",
    "joinquery = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b inner join users u on b.borrowed_by = u.user_id\n",
    "ORDER BY book_id\n",
    "'''\n",
    ";\n",
    "\n",
    "spark.sql(joinquery).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2ae00673-b05d-4c43-b5ad-93167ac408e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 90:=======================================>              (148 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      4|Book D|       Chris|       Brown|    null|   null|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# 2. LEFT JOIN\n",
    "joinquery = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b LEFT JOIN users u on b.borrowed_by = u.user_id\n",
    "ORDER BY book_id\n",
    "'''\n",
    ";\n",
    "\n",
    "spark.sql(joinquery).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3c066237-a3f3-4e76-a52f-1ec5fa82fb36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 93:===================================>                  (131 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|   null|  null|        null|        null|       I|   부산|\n",
      "|   null|  null|        null|        null|       J|   전주|\n",
      "|   null|  null|        null|        null|       G| 경기도|\n",
      "|   null|  null|        null|        null|       K|   광주|\n",
      "|   null|  null|        null|        null|       H|   대구|\n",
      "|   null|  null|        null|        null|       E|   null|\n",
      "|   null|  null|        null|        null|       D|   null|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "|      2|Book B|        Jane|       Smith|       B|   대전|\n",
      "|      3|Book C|       Emily|       Jones|       C| 경기도|\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#3. RIGHT JOIN\n",
    "#사용자의 책 대여 목록 -> 전체 사용자 -> 대여한 정보가 없을 때 null\n",
    "\n",
    "joinquery = '''\n",
    "SELECT book_id, title, author_fname, author_lname, username, address\n",
    "FROM books b RIGHT JOIN users u on b.borrowed_by = u.user_id\n",
    "ORDER BY book_id\n",
    "'''\n",
    ";\n",
    "\n",
    "spark.sql(joinquery).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8cdd3ad3-b5ab-4d6b-ae79-88c8ab705f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|username|address|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "|      5|Book E|        Anna|       Davis|       F|   서울|\n",
      "|      1|Book A|        John|         Doe|       A|   서울|\n",
      "+-------+------+------------+------------+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#특정지역 = 서울에 거주하는 사용자가 대여한 책 목록 \n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT book_id, title, author_fname, author_lname, username, address\n",
    "    FROM books b LEFT JOIN users u on b.borrowed_by = u.user_id\n",
    "    WHERE u.address == \"서울\"\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "773d7ec2-0af8-465e-9c60-beb8130a7784",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 129:==================================>                  (132 + 2) / 200]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+-----+\n",
      "|user_id|username|count|\n",
      "+-------+--------+-----+\n",
      "|      1|       A|    1|\n",
      "|      2|       B|    1|\n",
      "|      3|       C|    1|\n",
      "|      4|       D|    0|\n",
      "|      5|       E|    0|\n",
      "|      6|       F|    1|\n",
      "|      7|       G|    0|\n",
      "|      8|       H|    0|\n",
      "|      9|       I|    0|\n",
      "|     10|       J|    0|\n",
      "|     11|       K|    0|\n",
      "+-------+--------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#사용자별로 대여한 책 수 \n",
    "\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT user_id, username, count(book_id) as count\n",
    "    FROM users u LEFT JOIN books b on u.user_id = b.borrowed_by\n",
    "    GROUP BY user_id, username\n",
    "    ORDER BY user_id\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "76d8cc87-9328-4399-a58c-9968ed1775c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-----+-------------+\n",
      "|book_id| title|pages|book_category|\n",
      "+-------+------+-----+-------------+\n",
      "|      1|Book A|  300|         LONG|\n",
      "|      2|Book B|  250|        SHORT|\n",
      "|      3|Book C|  180|        SHORT|\n",
      "|      4|Book D|  320|         LONG|\n",
      "|      5|Book E|  270|        SHORT|\n",
      "+-------+------+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#book categry column 생성 , 300이상이면 long , 아니면 short\n",
    "\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT book_id, title,pages,CASE\n",
    "                                    WHEN pages >= 300 THEN 'LONG' ELSE 'SHORT'\n",
    "                                    END AS book_category\n",
    "    FROM books\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a5c99c53-14b9-4ee4-a1dc-f108fa56e1fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+---------------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|stock_situation|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+---------------+\n",
      "|      1|Book A|        John|         Doe|  300|         2005|            55|          1|           충분|\n",
      "|      2|Book B|        Jane|       Smith|  250|         2010|            40|          2|           보통|\n",
      "|      3|Book C|       Emily|       Jones|  180|         2015|            50|          3|           충분|\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|           충분|\n",
      "|      5|Book E|        Anna|       Davis|  270|         2008|            35|          6|           보통|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#stock_quanity > 50 이상 '충분', 30 이상 '보통', 미만 '부족'\n",
    "\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT *, CASE\n",
    "                WHEN stock_quantity >= 50 THEN '충분'\n",
    "                WHEN stock_quantity >= 30 THEN '보통'\n",
    "                ELSE '부족'\n",
    "                END AS stock_situation\n",
    "                \n",
    "    FROM books\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f5ee5f48-bfca-40b4-8051-05a5a1f24cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+-----+\n",
      "|author_fname|author_lname|count|\n",
      "+------------+------------+-----+\n",
      "|        Anna|       Davis|    1|\n",
      "+------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#대여가 많이 된 책의 작가를 조회\n",
    "spark.sql(\n",
    "    '''\n",
    "    SELECT author_fname, author_lname, count(book_id) as count\n",
    "    FROM books\n",
    "    GROUP BY author_fname, author_lname\n",
    "    ORDER BY count DESC\n",
    "    LIMIT 1\n",
    "    \n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "764dfc67-fa89-46e3-8bc2-129d6da33b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#발행 연도별 대여 현황"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ac47b8b4-3927-46e1-b882-7b9a32129856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|released_year|borrowed_count|\n",
      "+-------------+--------------+\n",
      "|         2012|             0|\n",
      "|         2010|             1|\n",
      "|         2005|             1|\n",
      "|         2008|             1|\n",
      "|         2015|             1|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\n",
    "    '''\n",
    "    SELECT released_year, count(borrowed_by) as borrowed_count\n",
    "    FROM books\n",
    "        GROUP BY released_year\n",
    "    '''\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "46d24c27-095a-4974-9005-e8ff9f290f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|address|borrowed_count|\n",
      "+-------+--------------+\n",
      "|   대전|             1|\n",
      "|   null|             0|\n",
      "|   전주|             0|\n",
      "| 경기도|             1|\n",
      "|   부산|             0|\n",
      "|   대구|             0|\n",
      "|   서울|             2|\n",
      "|   광주|             0|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#사용자의 지역별 책 대여 수 \n",
    "df1 = spark.sql(\n",
    "    '''\n",
    "    SELECT u.address, count(borrowed_by) as borrowed_count\n",
    "    FROM books b RIGHT JOIN users u on b.borrowed_by = u.user_id\n",
    "    GROUP BY u.address\n",
    "    '''\n",
    ")\n",
    "df1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "141af3ec-56b7-4c40-9b40-90dc15aff2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+-------+--------+-------+\n",
      "|book_id| title|author_fname|author_lname|pages|released_year|stock_quantity|borrowed_by|user_id|username|address|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+-------+--------+-------+\n",
      "|      4|Book D|       Chris|       Brown|  320|         2012|            75|       null|   null|    null|   null|\n",
      "+-------+------+------------+------------+-----+-------------+--------------+-----------+-------+--------+-------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "#대여되지 않은 책들 중 가장 페이지 수가 많은 책 \n",
    "df2 = spark.sql(\n",
    "    '''\n",
    "    SELECT *\n",
    "    FROM books b LEFT JOIN users u on b.borrowed_by = u.user_id\n",
    "    WHERE borrowed_by IS NULL\n",
    "    ORDER BY pages\n",
    "    LIMIT 1\n",
    "    '''\n",
    ")\n",
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d57aa2-573f-4b16-b4ce-40a6298fcd8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c1fbb259-f0ef-4e91-a557-105fd6dadd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(6) HashAggregate(keys=[address#40], functions=[count(borrowed_by#300L)])\n",
      "+- Exchange hashpartitioning(address#40, 200), ENSURE_REQUIREMENTS, [id=#2326]\n",
      "   +- *(5) HashAggregate(keys=[address#40], functions=[partial_count(borrowed_by#300L)])\n",
      "      +- *(5) Project [borrowed_by#300L, address#40]\n",
      "         +- SortMergeJoin [borrowed_by#300L], [user_id#38L], RightOuter\n",
      "            :- *(2) Sort [borrowed_by#300L ASC NULLS FIRST], false, 0\n",
      "            :  +- Exchange hashpartitioning(borrowed_by#300L, 200), ENSURE_REQUIREMENTS, [id=#2312]\n",
      "            :     +- *(1) Project [borrowed_by#300L]\n",
      "            :        +- *(1) Filter isnotnull(borrowed_by#300L)\n",
      "            :           +- *(1) Scan ExistingRDD[book_id#293L,title#294,author_fname#295,author_lname#296,pages#297L,released_year#298L,stock_quantity#299L,borrowed_by#300L]\n",
      "            +- *(4) Sort [user_id#38L ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(user_id#38L, 200), ENSURE_REQUIREMENTS, [id=#2317]\n",
      "                  +- *(3) Project [user_id#38L, address#40]\n",
      "                     +- *(3) Scan ExistingRDD[user_id#38L,username#39,address#40]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#실행계획, DAG 형태 분석\n",
    "\n",
    "df1.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e2015a28-7215-4f7b-aaed-bc8dcabbfc75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "TakeOrderedAndProject(limit=1, orderBy=[pages#297L ASC NULLS FIRST], output=[book_id#293L,title#294,author_fname#295,author_lname#296,pages#297L,released_year#298L,stock_quantity#384L,borrowed_by#300L,user_id#38L,username#39,address#40])\n",
      "+- SortMergeJoin [borrowed_by#300L], [user_id#38L], LeftOuter\n",
      "   :- *(2) Sort [borrowed_by#300L ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(borrowed_by#300L, 200), ENSURE_REQUIREMENTS, [id=#2364]\n",
      "   :     +- *(1) Project [book_id#293L, title#294, author_fname#295, author_lname#296, pages#297L, released_year#298L, CASE WHEN (book_id#293L = 3) THEN 50 ELSE stock_quantity#299L END AS stock_quantity#384L, borrowed_by#300L]\n",
      "   :        +- *(1) Filter isnull(borrowed_by#300L)\n",
      "   :           +- *(1) Scan ExistingRDD[book_id#293L,title#294,author_fname#295,author_lname#296,pages#297L,released_year#298L,stock_quantity#299L,borrowed_by#300L]\n",
      "   +- *(4) Sort [user_id#38L ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(user_id#38L, 200), ENSURE_REQUIREMENTS, [id=#2369]\n",
      "         +- *(3) Filter (isnull(user_id#38L) AND isnotnull(user_id#38L))\n",
      "            +- *(3) Scan ExistingRDD[user_id#38L,username#39,address#40]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.explain()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "32724b0c-4269-4de8-aed0-2626bffbcb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv로 save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "be9bba27-3c83-4ead-b108-53ca4949778d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df1.write.csv(\"data/output/result1.csv\", header = True, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "90966957-c880-45a9-ae60-b1ceb3836687",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "df2.write.csv(\"data/output/result2.csv\", header = True, mode = 'overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119fa25c-89a1-48ee-b31b-b96beb2e5ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c042cd-b371-4dea-a2fb-93d1819ccb4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c548c8-5f49-432e-9422-b5fd59a6922d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
