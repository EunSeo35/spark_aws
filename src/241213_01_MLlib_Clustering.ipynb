{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "202e306b-5ba0-4ac8-aed7-f010bddd1899",
   "metadata": {},
   "source": [
    "# Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0290a3-030b-48a4-aaa0-6a1c6e008dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/12/13 13:39:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('241213_01_MLlib_Clustering').getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c26423-1490-430f-b5a0-7beebf528ea1",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a5c09bc-0588-4115-b189-ddb2410f38e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (0, 0, 4.0),\n",
    "    (0, 1, 2.0),\n",
    "    (1, 1, 3.0),\n",
    "    (1, 2, 1.0),\n",
    "    (2, 0, 5.0),\n",
    "    (2, 2, 4.0)\n",
    "]\n",
    "\n",
    "columns = [\"user_id\",\"item_id\",\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13631768-5a6b-4953-baf4-9d45c9af60ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|user_id|item_id|rating|\n",
      "+-------+-------+------+\n",
      "|      0|      0|   4.0|\n",
      "|      0|      1|   2.0|\n",
      "|      1|      1|   3.0|\n",
      "|      1|      2|   1.0|\n",
      "|      2|      0|   5.0|\n",
      "|      2|      2|   4.0|\n",
      "+-------+-------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df= spark.createDataFrame(data, columns)\n",
    "rating_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4576c31-f239-460c-8308-22ea86872414",
   "metadata": {},
   "source": [
    "## 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fddcdadf-3064-4cf0-8156-46552d03895b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+\n",
      "|user_id|  0|  1|  2|\n",
      "+-------+---+---+---+\n",
      "|      0|4.0|2.0|0.0|\n",
      "|      1|0.0|3.0|1.0|\n",
      "|      2|5.0|0.0|4.0|\n",
      "+-------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# user_id, item_id matrix 생성\n",
    "\n",
    "user_item_matrix = rating_df.groupBy(\"user_id\").pivot(\"item_id\").avg('rating').fillna(0)\n",
    "user_item_matrix.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca47baf0-1ccf-4020-969e-130b79d7cbab",
   "metadata": {},
   "source": [
    "## Feature Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f6eb0d-243d-4989-b6fa-42fccfd8b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a3c3cca-5135-4935-a92c-f548f69dc110",
   "metadata": {},
   "outputs": [],
   "source": [
    "#벡터 생성\n",
    "assembler = VectorAssembler(inputCols = [\"0\",\"1\",\"2\"], outputCol = \"features\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b477b390-da65-4dbc-8f5a-6aa6c9f405c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_features= assembler.transform(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dd80fe5c-052a-4796-844d-18a0438e8acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+-------------+\n",
      "|user_id|  0|  1|  2|     features|\n",
      "+-------+---+---+---+-------------+\n",
      "|      0|4.0|2.0|0.0|[4.0,2.0,0.0]|\n",
      "|      1|0.0|3.0|1.0|[0.0,3.0,1.0]|\n",
      "|      2|5.0|0.0|4.0|[5.0,0.0,4.0]|\n",
      "+-------+---+---+---+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_features.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b33180a-aad6-4a91-b72c-846854c947cd",
   "metadata": {},
   "source": [
    "## Model 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "de030335-6584-4170-aa39-41fe254ea2bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "#모델 생성\n",
    "#k = cluster 개수\n",
    "kmeans = KMeans(k=2, seed =1, featuresCol = \"features\", predictionCol = \"cluster\")\n",
    "\n",
    "#모델 학습\n",
    "model = kmeans.fit(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ba198d06-3bc2-47a2-9f20-713f49fe1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#예측 \n",
    "clusters = model.transform(user_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6cc65a7-cbcf-46e0-a30c-6516b604cf0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---+---+-------------+-------+\n",
      "|user_id|  0|  1|  2|     features|cluster|\n",
      "+-------+---+---+---+-------------+-------+\n",
      "|      0|4.0|2.0|0.0|[4.0,2.0,0.0]|      0|\n",
      "|      1|0.0|3.0|1.0|[0.0,3.0,1.0]|      0|\n",
      "|      2|5.0|0.0|4.0|[5.0,0.0,4.0]|      1|\n",
      "+-------+---+---+---+-------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clusters.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951e9415-0ce2-4ce8-bc86-46518f077d68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15115e86-eacd-481f-a5a5-3a5edfa79a7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5b86cf20-1066-4902-ad2b-b92a4adc665b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105dc3d-c547-414c-a488-5a8a3fc059d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (spark_start)",
   "language": "python",
   "name": "spark_start"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
